\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[numbered]{bookmark}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{circuitikz}
\usetikzlibrary{arrows}
\usetikzlibrary{dsp,chains}

\title{APD Analysis and Simulations}

\author{JKP}

\date{\today}

\begin{document}
\maketitle

\input{common-part}

\section{APD}
\subsection{Output signal statistics}

Given an input average optical power $\bar{P}$, the number of $m$ primary electrons is Poisson distributed \cite{personick}: $m \sim \mathrm{Poisson}(\lambda)$, where $\lambda = (RP + I_d)dt/q$, $R$ is the photodiode responsivity; $I_d$ is the dark current; $dt$ is the sampling time of the received signal (sampling here means that the input signal is assumed to occur in discrete times); and $q$ is the electron charge.

The probability generating function (pgf) of the primaries distribution $p_1(m|P)$ is given by
\begin{equation}
g(z) = \sum_{r = 0}^{\infty} p_1(m|P)z^r = e^{\lambda(z-1)}
\end{equation}

Personick \cite{personick-comp-4methos} showed that the PGF of secondary electrons $p_2(n|1)$ (probability of generating $n$ secondary electrons from 1 primary) is
\begin{equation}
M(z) = \sum_{n = 0}^{\infty} p_2(n|1)z^n
\end{equation}
with $z = M[1 + \alpha(M-1)]^{-\beta}, \beta= (1-k)^{-1} > 1, \text{and}~G = (1-\alpha\beta)^{-1}.$

Later Balaban, Fleisher, and Zucker \cite{gain-distribution} showed that $p_2(n|m) \sim M(z)^m$, where $p_2(n|1) \sim M(z)$. That is, the gain of each primary electron is independent.
Therefore the probability of having $n$ output electrons for a given input optical power $P$ is

\begin{equation} \label{output-probability}
p(n|P) = \sum_{m = 0}^{\infty} p_2(n|m)p_1(m|P) =  \sum_{m = 0}^{\infty} p_2(n|m) \frac{\lambda^m e^{\lambda}}{m!}
\end{equation}
whose pgf is given by
\begin{align}
f(z) &= \sum_{k = 0}^{\infty}p(n|P)z^k = \sum_{k=0}^{\infty}\bigg(\sum_{m=0}^{\infty}p_1(m|P)p_2(n|m)\bigg)z^k \\ \nonumber
& = \sum_{m=0}^{\infty}p_1(m|P)\bigg(\sum_{k=0}^{\infty}p_2(n|m)z^k\bigg) \\ \nonumber
& = \sum_{m=0}^{\infty}p_1(m|P)M(z)^m \\
& = g(M(z)) = e^{\lambda(M(z)-1)}
\end{align}

From \cite{ber-saddlepoint-approx}, the pmf and its tails are given by
\begin{align}
p(n|P) = \frac{1}{2\pi j}\oint_C z^{-(n+1)}f(z)dz \\
p(N \geq n| P) = \frac{1}{2\pi j}\oint_{C+} \frac{z^{-n}}{z-1}f(z)dz \\
p(N \leq n| P) = \frac{1}{2\pi j}\oint_{C-} \frac{z^{-n}}{1-z}f(z)dz
\end{align}

We can apply the saddlepoint approximation to the inversion formulas: 

\subsection{pdf and tail probabilities including thermal noise and using the saddlepoint approximation}
\subsubsection{pdf}
The MGF of the signal including thermal noise with variance $\sigma^2$ is given by
\begin{equation}
\Phi (s) = \exp\Big(\lambda (M(e^s) - 1) + \frac{1}{2}\sigma^2s^2\Big)
\end{equation}

Thus, from the inversion equation we can write
\begin{align}
& K(s,x) = \log (\Phi(s)) - sx = \lambda (M(e^s) - 1) + \frac{1}{2}\sigma^2s^2 - sx \\
&\frac{\partial K(s,x)}{\partial s} = \lambda \frac{d}{ds}M(e^s) + \sigma^2s - x \\
&\frac{\partial^2 K(s,x)}{\partial s^2} = \lambda \frac{d^2}{ds^2}M(e^s) + \sigma^2
\end{align}

The main difficulty in evaluating the derivatives of $K(s,x)$ is in the fact that $M(e^s)$ has no explicit relation; it is only given in terms of the implicit relation
\begin{equation}
e^s = z = M(1 + \alpha(M-1))^{-\beta}
\end{equation}
where $\beta = (1 - k)^{-1}$, and $G = (1-\alpha\beta)^{-1}$.

Thus, we can write
\begin{align}
&\frac{d}{ds}M(s) = \frac{M(1 + \alpha (M-1))}{1 + \alpha(M-1) - \alpha\beta M} = \frac{p(s)}{q(s)}\\
&\frac{d^2}{ds^2}M(s) = \frac{p'q - pq'}{q^2}
\end{align}
where $p'(s) = M'(1 + \alpha(2M-1))$, and $q'(s) = \alpha M'(1 - \beta)$.

\begin{align}
&\frac{\partial K(s,x)}{\partial s} = \lambda \frac{M(1 + \alpha (M-1))}{1 + \alpha(M-1) - \alpha\beta M} + \sigma^2\log\Big(M(1 + \alpha(M-1))^{-\beta}\Big) - x \\
\end{align}

\subsubsection{tail}
Similarly for the tail probabilities, the MGF of the signal including thermal noise with variance $\sigma^2$ is given by
\begin{equation}
\Phi (s) = \exp\Big(\lambda (M(e^s) - 1) + \frac{1}{2}\sigma^2s^2\Big)
\end{equation}

Thus, from the inversion equation we can write
\begin{align}
& K(s,x) = \log \Big(\frac{\Phi(s)}{s}\Big) - sx = \lambda (M(e^s) - 1) + \frac{1}{2}\sigma^2s^2 - sx - \log(|s|) \\
&\frac{\partial K(s,x)}{\partial s} = \lambda \frac{d}{ds}M(e^s) + \sigma^2s - x - \frac{1}{s} \\
&\frac{\partial^2 K(s,x)}{\partial s^2} = \lambda \frac{d^2}{ds^2}M(e^s) + \sigma^2 + \frac{1}{s^2} 
\end{align}

The derivatives of $M(e^s)$ remain the same, and we can write

\begin{align}
&\frac{\partial K(s,x)}{\partial s} = \lambda \frac{M(1 + \alpha (M-1))}{1 + \alpha(M-1) - \alpha\beta M} + \sigma^2\log\Big(M(1 + \alpha(M-1))^{-\beta}\Big) - x -\frac{1}{s}
\end{align}

\subsection{Gaussian approximation}
The Gaussian approximation is equivalent to modeling equation \eqref{output-probability} as a Gaussian random variable \cite{personick-comp-4methos}. This approximation is fairly accurate because even for small power levels such as $-30$ dB, we have $\lambda = 125$ photons/symbol, assuming a rate of 50 GHz.

The current is equal to $I = \frac{nq}{dt} = \frac{n}{\lambda}(RP + I_d)$, where $n \sim p(n|P)$ as in \eqref{output-probability}. Thus, 
\begin{align}
& E(I) = RP + I_d \\
& \mathrm{Var}(I) = G^2F_A(G)\cdot 2q(RP_{rec} + I_d)1/dt
\end{align}
where $F_A(G)G^2$ corresponds to the mean square value of the random gain \cite{personick-comp-4methos}.

\textbf{Excess noise factor}
\begin{equation}
F_A(G) = k_AG + (1-k_A)\Big(2 - \frac{1}{G}\Big)
\end{equation}

\textbf{One-sided shot noise psd}
\begin{equation}
S_{shot} = G^2F_A(G)\cdot 2q(RP_{rec} + I_d)
\end{equation}

\textbf{APD noise figure:} The noise figure is defined as the $F_n = SNR_{in}(dB) - SNR_{out}(dB)$, where $SNR_{in}$ is defined as the SNR assuming only shot noise in a ideal photo counter, and $SNR_{out}(dB)$ is the SNR assuming the detection with the APD.

\underline{The excess noise factor is equal to the APD noise figure}, where the noise figure is defined as the ratio between the $SNR_{in}$ assuming detection with a photodiode with no dark current, and $SNR_{out}$ assuming detection with an APD with no dark current.
\begin{align}
F_n &= \frac{SNR_{in}}{SNR_{out}} = \frac{\frac{(R\bar{P})^2}{2qR\bar{P}\Delta f}}{\frac{(GR\bar{P})^2}{G^2F_A(G)\cdot 2qR\bar{P}\Delta f}} = F_A(G)
\end{align}

\subsection{Impact Ionization Factor}
% Table of ka
\begin{table}[t]
	\centering
	\begin{tabular}{p{3cm}|c}
		\hline
		Multiplication region material & $k_A$\\
		\hline
		Si & $\sim 0.1$ \\
		InAlAs & $\sim 0.2$ \\
		InP & $\sim 0.5$ \\
		InGaAs & 0.5 -- 0.7 \\
		Ge & 0.7 -- 1 \\
		\hline
	\end{tabular}
\end{table}

\subsection{Power Penalty vs Noise Figure}

Shot noise is dominant, and the BER is determined by the argument of the Q-function
\begin{equation}
\frac{\Delta P}{\sigma_{shot}} \propto \frac{GP}{\sqrt{G^2F_A(G)P}} = \sqrt{\frac{P}{F_A(G)}}
\end{equation}
Thus, 1-dB increase in the noise figure corresponds in 1-dB power penalty. However, for APD the noise figure depends on the operation point i.e., Gain.

\subsection{BER}

\begin{align} \label{eq:error-prob} \nonumber
SER = p(\mathcal{E}) = &\frac{1}{M}Q\bigg(\frac{GR(b_1 - a_0)}{\sigma_{0}}\bigg) \\ \nonumber 
& + \frac{1}{M}\sum_{k=1}^{M-2}\Bigg[Q\bigg(\frac{GR(a_k-b_k)}{\sigma_{k}}\bigg) + Q\bigg(\frac{GR(b_{k+1}-a_k)}{\sigma_{k}}\bigg)\Bigg] \\
& + \frac{1}{M}Q\bigg(\frac{GR(a_{M-1}-b_{M-1})}{\sigma_{M-1}}\bigg)
\end{align}
where $\sigma_{k}^2$ is the noise variance of the $i$th level:
\begin{equation}
\sigma_{k}^2 = \sigma_{th}^2 + G^2F_A(G)\cdot 2q(RP_{k} + I_d)R_s + RIN\cdot (RGP_{k})^2R_s 
\end{equation}

In the case of equally-spaced levels:
\begin{equation}
SER = \frac{1}{M}Q\bigg(\frac{\Delta P}{\sigma_{0}}\bigg) + \frac{2}{M}Q\bigg(\frac{\Delta P}{\sigma_{1}}\bigg) + \ldots + \frac{1}{M}Q\bigg(\frac{\Delta P}{\sigma_{M-1}}\bigg)
\end{equation}
where $\Delta P = \frac{2\bar{P}}{M-1}\frac{1-r_{ex}}{1 + r_{ex}}$ is the level spacing.

The BER can be calculated by assuming Gray coding:
\begin{equation}
BER = \frac{SER}{\log_2 M}
\end{equation}

When shot noise or RIN are dominant the BER is dominated by the BER of the last level. Thus, we can write
\begin{align}
BER \approx \frac{1}{M\log_2 M}Q\bigg(\frac{\Delta P}{\sigma_{M-1}}\bigg)
\end{align}


\section{Level spacing optimization}

One heuristic to minimize \eqref{eq:error-prob} is to make all error events equally likely. That is,
\begin{align} \label{eq:level-opt-condition} \nonumber
Q\bigg(\frac{GR(b_1 - a_0)}{\sigma_{0}}\bigg) =& \ldots = Q\bigg(\frac{GR(a_k-b_k)}{\sigma_{k}}\bigg) = Q\bigg(\frac{GR(b_{k+1}-a_k)}{\sigma_{k}}\bigg) = \ldots = Q\bigg(\frac{GR(a_{M-1}-b_{M-1})}{\sigma_{M-1}}\bigg) \\
& \frac{GR(b_k-a_{k-1})}{\sigma_{k-1}} = \frac{GR(a_{k}-b_k)}{\sigma_{k}} = \xi,~k = 1, \ldots, M-1
\end{align}

where $\xi$ depends on the target BER 
This way the BER is given by
\begin{equation}
\xi = Q^{-1}\bigg(\frac{M\cdot BER\log_2 M}{2(M-1)}\bigg)
\end{equation}
%log2(this.M)*BERtarget*(this.M/(2*(this.M-1)))

From \eqref{eq:level-opt-condition} we have the following equations
\begin{equation}
\begin{cases}
b_k - a_{k-1} = \sigma_{k-1}\frac{\xi}{GR} \\
a_k - b_k = \sigma_{k}\frac{\xi}{GR}
\end{cases}, k = 1, \ldots, M-1
\end{equation}

Solving for $a_k$
\begin{equation} \label{eq:level-spacing-opt}
a_k = a_{k-1} + \frac{\xi}{GR}(\sigma_{k-1} + \sigma_k), k = 1, \ldots, M-1
\end{equation}

Given $a_{k-1}$, $\sigma_{k-1}$, $a_k$ can be calculated sequentially. Moreover, since $\sigma_k^2$ is a quadratic function of $a_k$, \eqref{eq:level-spacing-opt} can be written as a quadratic function of $a_k$

\textbf{Check limiting cases when thermal noise is dominant and when shot noise is dominant.}

% Making $\delta = \frac{\xi}{GR}$ and given $a_{k-1}$, $\sigma_{k-1}$ can be determined and we can solve for $a_k$.

% \begin{align}
% & \frac{a_k - a_{k-1}}{\delta} - \sigma_{k-1} =  \sigma_k \\
% & \frac{a_k - a_{k-1} - \sigma_{k-1}\delta}{\delta} =  \sigma_k \\
% & \frac{(a_k - a_{k-1} - \sigma_{k-1}\delta)^2}{\delta^2} =  \sigma_k^2 \\
% & \frac{(a_k - a_{k-1} - \sigma_{k-1}\delta)^2}{\delta^2} =  \alpha + \beta a_k+ \gamma a_k^2 \\
% & \frac{(a_k - a_{k-1} - \sigma_{k-1}\delta)^2}{\delta^2} =  \alpha + \beta a_k+ \gamma a_k^2 \\
% & \frac{(a_k - c_1)^2}{\delta^2} =  \alpha + \beta a_k+ \gamma a_k^2 \\
% & a_k^2 - 2a_kc_1 + c_1^2 =  \delta^2\alpha + \delta^2\beta a_k+ \delta^2\gamma a_k^2 \\
% & a_k^2(1 - \delta^2\gamma) - a_k(2c_1 + \delta^2\beta) + c_1^2 - \delta^2\alpha = 0
% \end{align}

% $c_1 = a_{k-1} + \sigma_{k-1}\delta$

% Sanity check: if shot noise is dominant ($\alpha = \gamma = 0$, $\sigma_k^2 = \beta a_k$, $a_0 = 0$)
% \begin{align}
% & a_k^2 - a_k(2c_1 + \delta^2\beta) + c_1^2 = 0 \\
% & a_k = \frac{(2c_1 + \delta^2\beta) \pm \sqrt{(2c_1 + \delta^2\beta)^2 - 4c_1^2}}{2} \\
% & a_k = \frac{(2c_1 + \delta^2\beta) \pm \sqrt{4c_1\delta^2\beta + \delta^4\beta^2}}{2}
% \end{align}

\section{APD Gain Optimization}

The gain and level-spacing optimization can be done in terms of two distinct design objectives: (i) minimize BER, and (ii) maximize the margin. 

In the BER minimization design, given a received power, we calculate the optimal APD gain that leads to the minimum BER. This is the traditional approach to minimize the BER. Furthermore, this design approach is only reasonable if we assume equally-spaced levels. For optimized level spacing the BER can be made arbitrarily close to zero.

In the margin maximization design, we calculate the minimum received power required to achieve the target BER. In the case of optimized level-spacing the target BER is ensured in the level-optimization part, and the APD gain optimization essentially has to minimize the average power.

\subsection{BER minimization}
Since for equally-spaced levels the BER is dominated by the BER of the highest level, we can optimize the gain by optimizing the SNR of the last level. Thus,
\begin{align} \label{eq:Gopt-ber} \nonumber
G_{opt} &= \arg\max_{G} \frac{\Delta P^2}{\sigma_{th}^2 + G^2F_A(G)\cdot 2q(RP_{M-1} + I_d)R_s + RIN\cdot (RGP_{M-1})^2R_s} \\ \nonumber
& = \arg\max_{G}\frac{G^2P^2_{M-1}\frac{(1-r_{ex})^2}{(M-1)^2}}{\sigma_{th}^2 + G^2F_A(G)\cdot 2q(RP_{M-1} + I_d)R_s + RIN\cdot (RGP_{M-1})^2R_s} \\ \nonumber
& = \arg\max_{G}\frac{G^2P^2_{M-1}\frac{(1-r_{ex})^2}{(M-1)^2}}{\sigma_{th}^2 + G^2\Big(k_AG + (1-k_A)\Big(2 - \frac{1}{G}\Big)\Big)\cdot 2q(RP_{M-1} + I_d)R_s + RIN\cdot (RGP_{M-1})^2R_s} \\ \nonumber
& = \arg\max_{G}\frac{G^2P^2_{M-1}\frac{(1-r_{ex})^2}{(M-1)^2}}{\sigma_{th}^2 + \Big(k_AG^3 + 2(1-k_A)G^2 - (1-k_A)G\Big)\cdot 2q(RP_{M-1} + I_d)R_s + RIN\cdot (RGP_{M-1})^2R_s} \\
& = \arg\max_{G}\frac{aG^2}{bG^3 + cG^2 + dG + e}
\end{align}
where $P_{M-1}$ refers to the optical power of the highest level before the APD.

\begin{align}
& a = P^2_{M-1}\frac{(1-r_{ex})^2}{(M-1)^2} \\
& b = 2qk_A(RP_{M-1} + I_d)R_s \\
& c = 2(1-k_A) + RIN\cdot (RP_{M-1})^2R_s \\
& d = -2q(1-k_A)(RP_{M-1} + I_d)R_s \\
& e = \sigma_{th}^2 
\end{align}

The optimal gain is a solution to the equation
\begin{align}
& \frac{\partial}{\partial G}\bigg(\frac{aG^2}{bG^3 + cG^2 + dG + e}\bigg) = 0 \\
& bG^3 = dG + 2e 
\end{align}

\subsection{Receiver sensitivity or margin maximization}

We would like to determine the APD gain that leads to the maximum margin i.e., the smallest received power required to achieve the target BER. Formally,
\begin{align}
&\min_G \bar{P} \\
&\text{subject to } BER(G, P) = BER_{target}
\end{align}

For equally-spaced levels we can write instead
\begin{align}
&\min_G P_{M-1} \\
&\text{subject to } \frac{\Delta P}{\sigma_{M-1}} = Q^{-1}\Big(M\log_2 MBER_{target}\Big)
\end{align}

Using Lagrange Multipliers we have the following set of equations:
\begin{align}
\begin{cases}
& \lambda \frac{\partial}{\partial G} \frac{\Delta P}{\sigma_{M-1}} = 0 \\
& 1 + \lambda \frac{\partial}{\partial P_{M-1}} \frac{\Delta P}{\sigma_{M-1}} = 0 \\
& \frac{\Delta P}{\sigma_{M-1}} = Q^{-1}\Big(M\log_2 MBER_{target}\Big)
\end{cases}
\end{align}

Which leads to non-linear set of equations.

\subsection{Gain optimization with optimized level spacing}

Given $G$ find $\min\bar{P}$ that meets the target BER. This is also the solution to highest power margin improvement.

\begin{algorithm}
\caption{Matlab level spacing optimization given $G$}
\label{level-space-opt-given-G}
\begin{algorithmic}[1]
\State noiseSTD = apd.stdNoise(this, noiseBW, N0, RIN);
\State mpam.optimize$\_$level$\_$spacing$\_$gauss$\_$approx(sim.BERtarget, tx.rexdB, noiseSTD); $\%$ PAM levels are the smallest to achieve target BER
\end{algorithmic}
\end{algorithm}

We have two scenarios: (i) given input power what is the optimal gain, and (ii) find gain that minimizes required input power.

\section{Frequency Response}

When the avalanche build-up time dominates the frequency response we have \cite{}

\begin{equation}
G_{APD}(f) = \frac{1}{1 + (2\pi fMt_i)^2}
\end{equation}
where $M$ is the APD gain, and $t_i$ is the intrinsic response time given by \eqref{eq:ti}, which is a scattering limited transit time of carrier in the avalanche region. The product $t_iM$ is called the avalanche build-up time \cite{frequency-reponse-InP-InGaAs}.

\begin{equation}
t_i = Nk_a\frac{l_a}{\nu}
\end{equation}
where $N$ is a slowly varying factor from $1/3$ to 2, $l_a$ is the avalanche region width, and $\nu$ is the effective carrier drift velocity in the avalanche region.

We consider that the APD has bandwidth $W_{APD}$, and that the frequency response is given by
\begin{equation}
H_{APD}(f) = \frac{1}{\sqrt{1 + \bigg(\frac{f}{W_{APD}}\bigg)^2}}
\end{equation}

The noise bandwidth is given by
\begin{equation}
\Delta f = \int_{0}^{\infty} |H_{APD}(f)|^2 df = W_{APD}\frac{\pi}{4}
\end{equation}

Another common representation of the APD frequency response is to use the deterministic exponential decay: $h_{APD}(t) = Be^{-tB}u(t)$. Which corresponds to the frequency response:
\begin{equation}
H_{APD}(f) = \frac{1}{1 + j\frac{f}{W_{APD}}}
\end{equation}

The amplitude response of this transfer function is identical to the one used before. However, their phase responses are different.

\section{System design}
\begin{figure}[!h]
	\centering
	\begin{tikzpicture}[auto, node distance=2cm,>=latex']   
	
	% Place nodes using a matrix
	\matrix (m1) [row sep=4mm, column sep=4mm]
	{
		%--------------------------------------------------------------------
		\node [coordinate, label=$x(t)$] (m00) {};          &
		\node [dspfilter] (m01) {$p(t)$};   		&
		\node [dspfilter] (m02) {$h_{ch}(t)$};   		&
		\node [dspadder] (m03) {};   		&
		\node [dspfilter] (m04) {$h_{APD}(t)$}; 	&
		\node [dspadder] (m05) {};   		&
		\node [dspfilter] (m06) {$h_W(t)$}; &
		\node [dspfilter] (m07) {$h_{rx}(t)$}; &
		\node [coordinate, label=$z(t)$] (m08) {}; \\
		&
		&
		&
		\node [coordinate] (shot) {}; &
		&
		\node [coordinate] (thermal) {}; &
		&
		& \\
		%--------------------------------------------------------------------
	};
	\foreach \i [evaluate = \i as \j using int(\i+1)] in {0, 1,2,3, 4,5,6, 7}
		\draw[dspflow] (m0\i) -- (m0\j);
	
	\draw[dspconn] (shot) -- node[below] {$s(t)$} (m03); %-- node[midway, above] {$p[n]$} 
	\draw[dspconn] (thermal) -- node[below] {$n(t)$} (m05);
	\end{tikzpicture}
	\caption{System model block diagram.} \label{fig:sys-diagram}
\end{figure}


\subsection{Noise whitening filter}

Shot noise is shaped by the APD frequency response, and consequently the total noise (shot plus thermal noise) is not white. Thus, we must use the whitening filter so that the total noise is white:

\begin{align} \nonumber
|H_W(f)|^2\Big(N_0 + |H_{APD}(f)|^2S_{shot}\Big) &= N_0 + S_{shot} \\ \nonumber
|H_W(f)|^2 &= \frac{N_0 + S_{shot}}{N_0 + |H_{APD}(f)|^2S_{shot}} \\
 &= \frac{1 + \frac{N_0}{S_{shot}}}{\frac{N_0}{S_{shot}} + |H_{APD}(f)|^2}
\end{align}

The effect of this filter in the performance is virtually negligible. Probably this occurs because the temporal correlation of shot noise is not that significant compared to the symbol period.

\subsection{Detected noise variance}

The total noise after the noise whitening filter is
\begin{equation}
w(t) = h_W(t)\ast h_{APD} \ast s(t) + h_W(t)\ast n(t)
\end{equation}

The noise variance is given by
\begin{equation}
\text{Var}(w(t)) = \sigma_s^2(t)\ast \Big((h_W(t)\ast h_{APD}(t))(h_W^*(t)\ast h_{APD}^*(t)) + \sigma^2_n \int_{-\infty}^{\infty} |h_W(\tau)|^2 d\tau
\end{equation}

If thermal noise is dominant, then $h_W(t)\ast h_{APD} \approx h_APD(t)$:
\begin{equation}
\text{Var}(w(t)) = \sigma_s^2(t)\ast (h_{APD}(t) \ast h_{APD}^*(t)) + \sigma^2_n
\end{equation}

If shot noise is dominant, then $h_W(t)\ast h_{APD} \approx \delta(t)$:
\begin{equation}
\text{Var}(w(t)) = \sigma_s^2(t) + \sigma^2_n \int_{-\infty}^{\infty} |h_W(\tau)|^2 d\tau
\end{equation}

\subsection{ISI enhanced signal-dependent noise}

In the case of interest when shot noise is dominant, the shot noise is approximately white as shown in the previous section; however, it is still time-dependent. This time dependency will enhance the effective variance of the noise after matched filtering and equalization.

Fig. \ref{fig:eq_discrete_time} shows the equivalent discrete-time system model, where $x[n]$ are the transmitted symbols, $p[n]$ corresponds to the pulse shape and includes all frequency response limitations such as transmitter filter, modulator, fiber, APD, and whitening filter.  $s[n]$ is the whitened signal dependent noise whose variance is determined by $x[n]\ast \tilde{p}[n]$, where $\tilde{p}[n]$ is the impulse response corresponding to the filter before the APD i.e., transmitter, modulator, and fiber. Note, that $s[n]$ is signal-dependent only for simplicity. The effects of signal-independent noises can be added later by superposition. $g[n]$ corresponds to the cascade of the matched filter $h[n] = p^*[-n]$ and the equalizer $h_{eq}[n]$. 

\begin{figure}[!h]
	\centering
	\begin{tikzpicture}[auto, node distance=2cm,>=latex']   
	
	% Place nodes using a matrix
	\matrix (m1) [row sep=4mm, column sep=8mm]
	{
		%--------------------------------------------------------------------
		\node [coordinate] (input) {};          &
		\node [dspfilter] (xz) {$p[n]$};   		&
		\node [dspadder] (adder) {};   		&
		\node [dspfilter] (xeq) {$g[n] = h[n]\ast h_{eq}[n]$}; 	&
		\node [coordinate] (output) {}; \\
		&
		&
		\node [coordinate] (noise) {}; &
		&
		& \\
		%--------------------------------------------------------------------
	};
	\draw[dspconn]  (input) node[left] {$x[n]$} -- (xz);
	\draw[dspconn] (xz) -- (adder); %-- node[midway, above] {$p[n]$} 
	\draw[dspconn] (adder) -- (xeq);
	\draw[dspconn] (noise) node[below] {$s[n]$} -- (adder);
	\draw[dspconn] (xeq) -- (output)  node[right] {$y[n]$};    
	\end{tikzpicture}
	\caption{Equivalent discrete-time system with symbol-rate sampling} \label{fig:eq_discrete_time}
\end{figure}

Using the equivalent discrete-time system:
\begin{align}
y_s[n] &= h_{eq}[n]\ast(s[n]\ast h[n]) \\
& = \sum_{m=-L_1}^{L_2} s[n-m]g[m]
\end{align}
where $g[n] = h_{eq}[n]\ast h[n]$

For the variance
\begin{align}
\text{Var}(y_s[n]) &= E(y_s[n]y_s^*[n])\\
& = E\bigg[\bigg(\sum_{m_1=-L_1}^{L_2} s[n-m_1]g[m_1]\bigg)\bigg(\sum_{m_2=-L_1}^{L_2} s^*[n-m_2]g^*[m_2]\bigg)\bigg] \\
& = E\bigg[\bigg(\sum_{m_1=-L_1}^{L_2}\sum_{m_2=-L_1}^{L_2}  s[n-m_1]s^*[n-m_2]g[m_1]g^*[m_2]\bigg)\bigg] \\
& = \sum_{m_1=-L_1}^{L_2}\sum_{m_2=-L_1}^{L_2}  E\Big(s[n-m_1]s^*[n-m_2]\Big)g[m_1]g^*[m_2]
\end{align}

Assuming first that the variance is time-independent: $E\Big(s[n-m_1]s^*[n-m_2]\Big) = \sigma^2\delta[m_1-m_2]$

\begin{align}
\text{Var}(y_s[n]) & = \sigma^2\sum_{m=-L_1}^{L_2} g[m]g^*[m] \\
& = \sigma^2\sum_{m=-L_1}^{L_2} g[m]\bigg(\sum_{\nu= -N_1}^{N_2} h^*_{eq}[m-\nu]h^*[\nu]\bigg) \\
& = \sigma^2\sum_{\nu= -N_1}^{N_2} h^*_{eq}[\nu] \sum_{m=-L_1}^{L_2} g[m]h^*[\nu-m] \\
& = \sigma^2\sum_{\nu= -N_1}^{N_2} h^*_{eq}[\nu]\delta[\nu] \\
& = \sigma^2h_{eq}[0]
\end{align}

Now assuming that the variance is time-dependent: $E\Big(s[n-m_1]s^*[n-m_2]\Big) = \sigma^2[n-m_1]\delta[m_1-m_2]$

\begin{align}
\text{Var}(y_s[n]) & = \sum_{m=-L_1}^{L_2} \sigma^2[n-m]g[m]g^*[m] \\
& = \sigma^2[n]\ast (g[n]g^*[n])
\end{align}

The variance $\sigma^2[n]$ is a function of time because the noise is signal dependent, but the noise has no temporal correlation.

\begin{thebibliography}{9}
\bibitem{personick-comp-4methos} Personick, S. D., Balaban, P., Bobsin, J. H., and Kumar, P.; ``R.A Detailed Comparison of Four Approaches to the Calculation of the Sensitivity of Optical Fiber System Receivers,'' \emph{IEEE Transactions on Communications}, 1976.

\bibitem{gain-distribution} Balaban, P., Fleischer, P. E., and Zucker, H.; ``The Probability Distribution of Gains in Avalanche Photodiodes,'' \emph{IEEE Transactions on Electron Devices}, 1976.

\bibitem{ber-saddlepoint-approx} Carl Helstrom; ``Performance Analysis of Optical Receivers by the Saddlepoint Approximation,'' \emph{IEEE Transactions on Communications}, 1979.

\bibitem{personick} Personick, S. D.; ``Statistics of a General Class of Avalanche Detectors With Applications to Optical Communication,'' \emph{The Bell SystemTechnical Journal}, 1971.

\bibitem{agilent-RIN-measurement} Product Note 86100-7; ``Digital Communication Analyzer (DCA), Measure Relative Intensity Noise (RIN),'' Agilent Technologies. 

\bibitem{frequency-reponse-InP-InGaAs} Yasuda, K. and Mikawa, T. and Kishi, Y. and Kaneda, T.; ``Multiplication-dependent frequency responses of InP/ InGaAs Avalanche Photodiodes,'' 1981.



\end{thebibliography}

\end{document}